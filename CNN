卷积神经网络：


CNN的部件其实大致分为三个，卷积层、池化层（pooling）、全连接层，这也是LeNet-5的经典结构，之后大部分CNN网络其实都是在这三个基本部件上做各种组合和改进。
卷积池化交替出现，保证提取特征的同时也强制模糊增加特征的旋转不变性。

用K近邻分类器的优点是训练阶段毫不费事，但是测试阶段随着样本集的增大可是要了命了。然而，CNN与之相反，它的训练过程较为漫长，而测试阶段时耗很少。




基于CNN的图像分类我们第三部分介绍了传统方法下的图像分类流程：特征提取+特征表达+分类。
而CNN将这些步骤合并到一个统一整体中（当然你也可以用CNN来提取特征用其他分类器训练分类）。
CNN自YannLecun的手写字符识别及AlexNet在ImageNet夺冠后声名大噪，广泛运用到很多图像分类的场景中。
4.1 卷积层下面，卷积层的相关知识。
4.1.1 权值共享和权值共享
CNN的局部连接和权值共享通过卷积核来实现，卷积核也就是“感受野”，感受野使得训练参数，训练复杂度大为减少。
（具体怎么算可以参考LeNet5）
4.1.2 降采样
降采样主要体现在池化层，或称为降采样层中。使得特征映射的resolution再次减少。而不论是Pooling层还是卷积层，步长stride也是降采样的有力手段。
4.2 激活函数层为什么要激活函数？为什么要非线性的激活函数？因为没有激活函数，或者激活函数是线性的，就算你亿万层的神经网络相当于没有！！！
4.3 分类层CNN分类中，常见的分类函数就是多项逻辑斯蒂回归模型，Softmax回归模型。它是基于概率的分类模型，利用最小化负对数似然函数来优化。
5 直观的理解排名第一的答案里面的图片是一个简单的说明，简单的概括就是CNN是一个层级递增的结构，像人理解文章一样，先逐字逐句，再段落大意，再全文的理解，
CNN也是从像素，边缘，局部形状一直到整体形状的感知。


